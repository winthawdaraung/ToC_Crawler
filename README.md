# ğŸï¸ F1 Driver Crawler

**TOC Assignment** â€” Web crawler for 130+ Formula 1 drivers, extracting data from
Wikipedia using Python's `re` module, displayed in a Flask web application.

> GitHub link is displayed in the header and footer of the web application.

---

## ğŸ“‚ Project Structure

```
f1-crawler/
â”œâ”€â”€ scraper.py              â† web crawler + ALL regex patterns
â”œâ”€â”€ app.py                  â† Flask web application
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Procfile                â† for Render/Heroku
â”œâ”€â”€ render.yaml             â† one-click Render deploy
â”œâ”€â”€ data/
â”‚   â””â”€â”€ drivers.json        â† auto-generated by scraper
â”œâ”€â”€ templates/V
â”‚   â”œâ”€â”€ index.html          â† driver list page
â”‚   â””â”€â”€ driver.html         â† individual driver detail
â””â”€â”€ static/
    â”œâ”€â”€ css/style.css
    â””â”€â”€ js/main.js
```

---

## ğŸ”´ Regular Expressions (11 patterns â€” all in scraper.py)

| # | Name | What it extracts |
|---|------|-----------------|
| RE-1 | `RE_DRIVER_LINK` | Driver `/wiki/` hrefs from list pages |
| RE-2 | `RE_PAGE_TITLE` | Full name from `<title>` tag |
| RE-3 | `RE_DOB` | Date of birth in 2 different formats |
| RE-4 | `RE_BIRTHPLACE` | City/country of birth |
| RE-5 | `RE_NATIONALITY` | Driver nationality |
| RE-6 | `RE_TEAM` | Current F1 team from infobox |
| RE-7 | `RE_TITLES` | World Championship titles (handles word numbers too) |
| RE-8 | `RE_STARTS` | Number of race starts |
| RE-9 | `RE_NUMBER` | Racing car number |
| RE-10 | `RE_PODIUMS` | Total podium finishes |
| RE-11 | `RE_POLES` | Total pole positions |

---

## â–¶ï¸ Run Locally

```bash
# Clone the repo
git clone https://github.com/YOUR_USERNAME/f1-crawler.git
cd f1-crawler

# Install dependencies
pip install -r requirements.txt

# Step 1: Crawl Wikipedia (~2-3 minutes, scrapes 130+ drivers)
python scraper.py

# Step 2: Start the web app
python app.py
# Open: http://127.0.0.1:5000
```

---

## â˜ï¸ Deployment Guide

### Option A â€” Render.com (Recommended, Free)

1. Push this repo to GitHub.
2. Go to [render.com](https://render.com) â†’ **New â†’ Web Service**
3. Connect your GitHub repository.
4. Fill in:
   - **Build Command:** `pip install -r requirements.txt && python scraper.py`
   - **Start Command:** `gunicorn app:app`
5. Click **Create Web Service**.
6. Your public URL will appear at the top (e.g. `https://f1-crawler.onrender.com`).

> âš¡ Alternatively, just push the `render.yaml` file and click "Deploy to Render".

### Option B â€” Railway

```bash
npm install -g @railway/cli
railway login
railway init        # choose "Empty project"
railway up          # auto-detects Procfile
```

Railway auto-assigns a public URL.

### Option C â€” PythonAnywhere (Free tier)

1. Upload all files via the **Files** tab.
2. Open a Bash console:
   ```bash
   pip3.10 install --user flask gunicorn
   python scraper.py
   ```
3. Go to **Web** tab â†’ Add new web app â†’ Manual config â†’ Python 3.10.
4. Set WSGI file to point to your `app.py`:
   ```python
   import sys
   sys.path.insert(0, '/home/YOUR_USERNAME/f1-crawler')
   from app import app as application
   ```
5. Reload the web app. âœ…

---

## ğŸ“¸ Features

- **130+ F1 drivers** scraped from Wikipedia
- Live **search + filter** by nationality and team
- Individual **driver detail pages**
- **11 regex patterns** for data extraction (RE-1 through RE-11)
- REST API at `/api/drivers` and `/api/stats`
- Responsive F1-themed dark UI

---

## ğŸ” API Endpoints

| Endpoint | Description |
|----------|-------------|
| `GET /api/drivers` | All drivers (JSON) |
| `GET /api/drivers?q=hamilton` | Search by name |
| `GET /api/drivers?nationality=British` | Filter by nationality |
| `GET /api/drivers?team=Mercedes` | Filter by team |
| `GET /api/stats` | Aggregated stats (by nationality, team, decade) |

---

## ğŸ‘¥ Team Members

- Member 1 (Student ID)
- Member 2 (Student ID)
- Member 3 (Student ID)
- Member 4 (Student ID)
- Member 5 (Student ID)

**Due:** March 4, 2026 before 9 AM
